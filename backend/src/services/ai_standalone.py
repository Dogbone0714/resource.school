"""
ç¨ç«‹ AI æ¨è–¦æœå‹™æ¨¡çµ„
ä½¿ç”¨ Pandas å’Œ scikit-learn é€²è¡Œå­¸ç³»æ¨è–¦åˆ†æ
ä¸ä¾è³´å…¶ä»–æœå‹™æ¨¡çµ„
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from typing import List, Dict, Any, Tuple
import json
import pickle
import os

class DepartmentRecommendationAI:
    """å­¸ç³»æ¨è–¦ AI ç³»çµ±"""
    
    def __init__(self):
        self.model = None
        self.label_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        self.departments = []
        self.feature_columns = []
        self.model_path = "ai_models/department_recommendation_model.pkl"
        self.scaler_path = "ai_models/scaler.pkl"
        self.encoder_path = "ai_models/label_encoder.pkl"
        
        # ç¢ºä¿æ¨¡å‹ç›®éŒ„å­˜åœ¨
        os.makedirs("ai_models", exist_ok=True)
        
        # åˆå§‹åŒ–æˆ–è¼‰å…¥æ¨¡å‹
        self._initialize_model()
    
    def _initialize_model(self):
        """åˆå§‹åŒ–æˆ–è¼‰å…¥æ¨¡å‹"""
        if os.path.exists(self.model_path):
            self._load_model()
        else:
            self._create_mock_data_and_train()
    
    def _create_mock_data_and_train(self):
        """å‰µå»ºå‡è³‡æ–™ä¸¦è¨“ç·´æ¨¡å‹"""
        print("ğŸ¤– å‰µå»ºå‡è³‡æ–™ä¸¦è¨“ç·´å­¸ç³»æ¨è–¦æ¨¡å‹...")
        
        # ç”Ÿæˆå‡è³‡æ–™
        mock_data = self._generate_mock_data()
        
        # æº–å‚™ç‰¹å¾µå’Œæ¨™ç±¤
        X, y = self._prepare_features_and_labels(mock_data)
        
        # è¨“ç·´æ¨¡å‹
        self._train_model(X, y)
        
        # å„²å­˜æ¨¡å‹
        self._save_model()
        
        print("âœ… æ¨¡å‹è¨“ç·´å®Œæˆä¸¦å„²å­˜")
    
    def _generate_mock_data(self) -> pd.DataFrame:
        """ç”Ÿæˆå‡è³‡æ–™"""
        np.random.seed(42)  # ç¢ºä¿çµæœå¯é‡ç¾
        
        n_samples = 1000
        
        # ç”Ÿæˆå­¸ç§‘æˆç¸¾ (0-100)
        data = {
            'chinese_score': np.random.normal(75, 15, n_samples).clip(0, 100),
            'english_score': np.random.normal(80, 12, n_samples).clip(0, 100),
            'math_score': np.random.normal(70, 18, n_samples).clip(0, 100),
            'science_score': np.random.normal(75, 16, n_samples).clip(0, 100),
            'social_score': np.random.normal(78, 14, n_samples).clip(0, 100),
        }
        
        # ç”Ÿæˆèˆˆè¶£ç‰¹å¾µ (0-1 ä¹‹é–“çš„åˆ†æ•¸)
        interests = [
            'programming', 'mathematics', 'physics', 'chemistry', 'biology',
            'literature', 'history', 'art', 'music', 'sports', 'leadership',
            'research', 'communication', 'creativity', 'analysis'
        ]
        
        for interest in interests:
            data[f'interest_{interest}'] = np.random.beta(2, 5, n_samples)
        
        # ç”Ÿæˆç¤¾åœ˜ç¶“æ­·ç‰¹å¾µ
        data['club_leadership'] = np.random.binomial(1, 0.3, n_samples)
        data['club_tech'] = np.random.binomial(1, 0.4, n_samples)
        data['club_art'] = np.random.binomial(1, 0.2, n_samples)
        data['club_sports'] = np.random.binomial(1, 0.3, n_samples)
        data['club_academic'] = np.random.binomial(1, 0.5, n_samples)
        
        # ç”Ÿæˆç«¶è³½ç²çç‰¹å¾µ
        data['competition_math'] = np.random.binomial(1, 0.15, n_samples)
        data['competition_science'] = np.random.binomial(1, 0.12, n_samples)
        data['competition_programming'] = np.random.binomial(1, 0.08, n_samples)
        data['competition_language'] = np.random.binomial(1, 0.1, n_samples)
        data['competition_art'] = np.random.binomial(1, 0.05, n_samples)
        
        # ç”Ÿæˆå­¸ç³»æ¨™ç±¤ (åŸºæ–¼ç‰¹å¾µçš„é‚è¼¯è¦å‰‡)
        departments = []
        for i in range(n_samples):
            dept = self._assign_department_by_rules(data, i)
            departments.append(dept)
        
        data['department'] = departments
        
        return pd.DataFrame(data)
    
    def _assign_department_by_rules(self, data: Dict, idx: int) -> str:
        """æ ¹æ“šè¦å‰‡åˆ†é…å­¸ç³»"""
        # è¨ˆç®—å„é ˜åŸŸçš„ç¶œåˆåˆ†æ•¸
        tech_score = (
            data['math_score'][idx] * 0.3 +
            data['science_score'][idx] * 0.3 +
            data['interest_programming'][idx] * 100 * 0.2 +
            data['interest_mathematics'][idx] * 100 * 0.1 +
            data['club_tech'][idx] * 20 +
            data['competition_programming'][idx] * 30 +
            data['competition_math'][idx] * 20
        )
        
        engineering_score = (
            data['math_score'][idx] * 0.25 +
            data['science_score'][idx] * 0.35 +
            data['interest_physics'][idx] * 100 * 0.2 +
            data['interest_mathematics'][idx] * 100 * 0.1 +
            data['club_tech'][idx] * 15 +
            data['competition_math'][idx] * 25 +
            data['competition_science'][idx] * 25
        )
        
        business_score = (
            data['chinese_score'][idx] * 0.3 +
            data['english_score'][idx] * 0.3 +
            data['social_score'][idx] * 0.2 +
            data['interest_leadership'][idx] * 100 * 0.1 +
            data['interest_communication'][idx] * 100 * 0.1 +
            data['club_leadership'][idx] * 25 +
            data['competition_language'][idx] * 20
        )
        
        science_score = (
            data['math_score'][idx] * 0.3 +
            data['science_score'][idx] * 0.4 +
            data['interest_research'][idx] * 100 * 0.2 +
            data['interest_analysis'][idx] * 100 * 0.1 +
            data['club_academic'][idx] * 20 +
            data['competition_science'][idx] * 30 +
            data['competition_math'][idx] * 20
        )
        
        art_score = (
            data['chinese_score'][idx] * 0.3 +
            data['interest_art'][idx] * 100 * 0.4 +
            data['interest_creativity'][idx] * 100 * 0.3 +
            data['club_art'][idx] * 30 +
            data['competition_art'][idx] * 40
        )
        
        # é¸æ“‡åˆ†æ•¸æœ€é«˜çš„å­¸ç³»
        scores = {
            'è³‡è¨Šå·¥ç¨‹å­¸ç³»': tech_score,
            'é›»æ©Ÿå·¥ç¨‹å­¸ç³»': engineering_score,
            'å•†æ¥­ç®¡ç†å­¸ç³»': business_score,
            'æ•¸å­¸ç³»': science_score,
            'å¤–åœ‹èªæ–‡å­¸ç³»': art_score
        }
        
        return max(scores, key=scores.get)
    
    def _prepare_features_and_labels(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """æº–å‚™ç‰¹å¾µå’Œæ¨™ç±¤"""
        # åˆ†é›¢ç‰¹å¾µå’Œæ¨™ç±¤
        feature_columns = [col for col in data.columns if col != 'department']
        X = data[feature_columns].values
        y = data['department'].values
        
        # å„²å­˜ç‰¹å¾µåˆ—å
        self.feature_columns = feature_columns
        
        # ç·¨ç¢¼æ¨™ç±¤
        y_encoded = self.label_encoder.fit_transform(y)
        self.departments = self.label_encoder.classes_.tolist()
        
        return X, y_encoded
    
    def _train_model(self, X: np.ndarray, y: np.ndarray):
        """è¨“ç·´æ¨¡å‹"""
        # åˆ†å‰²è³‡æ–™
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # æ¨™æº–åŒ–ç‰¹å¾µ
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # è¨“ç·´éš¨æ©Ÿæ£®æ—æ¨¡å‹
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            class_weight='balanced'
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # è©•ä¼°æ¨¡å‹
        y_pred = self.model.predict(X_test_scaled)
        accuracy = np.mean(y_pred == y_test)
        
        print(f"ğŸ“Š æ¨¡å‹æº–ç¢ºç‡: {accuracy:.3f}")
    
    def _save_model(self):
        """å„²å­˜æ¨¡å‹"""
        with open(self.model_path, 'wb') as f:
            pickle.dump(self.model, f)
        
        with open(self.scaler_path, 'wb') as f:
            pickle.dump(self.scaler, f)
        
        with open(self.encoder_path, 'wb') as f:
            pickle.dump(self.label_encoder, f)
    
    def _load_model(self):
        """è¼‰å…¥æ¨¡å‹"""
        with open(self.model_path, 'rb') as f:
            self.model = pickle.load(f)
        
        with open(self.scaler_path, 'rb') as f:
            self.scaler = pickle.load(f)
        
        with open(self.encoder_path, 'rb') as f:
            self.label_encoder = pickle.load(f)
        
        # é‡å»ºç‰¹å¾µåˆ—åå’Œå­¸ç³»åˆ—è¡¨
        self.feature_columns = [
            'chinese_score', 'english_score', 'math_score', 'science_score', 'social_score',
            'interest_programming', 'interest_mathematics', 'interest_physics', 'interest_chemistry',
            'interest_biology', 'interest_literature', 'interest_history', 'interest_art',
            'interest_music', 'interest_sports', 'interest_leadership', 'interest_research',
            'interest_communication', 'interest_creativity', 'interest_analysis',
            'club_leadership', 'club_tech', 'club_art', 'club_sports', 'club_academic',
            'competition_math', 'competition_science', 'competition_programming',
            'competition_language', 'competition_art'
        ]
        self.departments = self.label_encoder.classes_.tolist()
    
    def analyze_student_data(self, student_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åˆ†æå­¸ç”Ÿè³‡æ–™ä¸¦ç”Ÿæˆæ¨è–¦"""
        # æå–å’Œè™•ç†å­¸ç”Ÿè³‡æ–™
        features = self._extract_features(student_data)
        
        # é æ¸¬å­¸ç³»
        predictions = self._predict_departments(features)
        
        # ç”Ÿæˆæ¨è–¦çµæœ
        recommendations = self._generate_recommendations(predictions, student_data)
        
        return recommendations
    
    def _extract_features(self, student_data: Dict[str, Any]) -> np.ndarray:
        """å¾å­¸ç”Ÿè³‡æ–™ä¸­æå–ç‰¹å¾µ"""
        features = np.zeros(len(self.feature_columns))
        
        # å­¸ç§‘æˆç¸¾
        academic_scores = student_data.get('academic_scores', {})
        score_mapping = {
            'chinese_score': 'chinese',
            'english_score': 'english', 
            'math_score': 'math',
            'science_score': 'science',
            'social_score': 'social'
        }
        
        for feature_name, score_key in score_mapping.items():
            if feature_name in self.feature_columns:
                idx = self.feature_columns.index(feature_name)
                features[idx] = academic_scores.get(score_key, 0)
        
        # èˆˆè¶£ç‰¹å¾µ
        interests = student_data.get('interests', [])
        interest_mapping = {
            'programming': ['ç¨‹å¼è¨­è¨ˆ', 'ç¨‹å¼', 'coding', 'è»Ÿé«”', 'è³‡è¨Š'],
            'mathematics': ['æ•¸å­¸', 'çµ±è¨ˆ', 'è¨ˆç®—'],
            'physics': ['ç‰©ç†', 'åŠ›å­¸', 'é›»å­¸'],
            'chemistry': ['åŒ–å­¸', 'å¯¦é©—'],
            'biology': ['ç”Ÿç‰©', 'ç”Ÿå‘½ç§‘å­¸'],
            'literature': ['æ–‡å­¸', 'èªæ–‡', 'å¯«ä½œ'],
            'history': ['æ­·å²', 'ç¤¾æœƒ'],
            'art': ['è—è¡“', 'ç¾è¡“', 'è¨­è¨ˆ'],
            'music': ['éŸ³æ¨‚', 'æ¨‚å™¨'],
            'sports': ['é‹å‹•', 'é«”è‚²', 'å¥èº«'],
            'leadership': ['é ˜å°', 'ç®¡ç†', 'çµ„ç¹”'],
            'research': ['ç ”ç©¶', 'å­¸è¡“', 'å¯¦é©—'],
            'communication': ['æºé€š', 'è¡¨é”', 'æ¼”è¬›'],
            'creativity': ['å‰µæ„', 'å‰µæ–°', 'å‰µä½œ'],
            'analysis': ['åˆ†æ', 'é‚è¼¯', 'æ€è€ƒ']
        }
        
        for interest_type, keywords in interest_mapping.items():
            feature_name = f'interest_{interest_type}'
            if feature_name in self.feature_columns:
                idx = self.feature_columns.index(feature_name)
                # è¨ˆç®—èˆˆè¶£åŒ¹é…åº¦
                match_score = sum(1 for interest in interests 
                                for keyword in keywords 
                                if keyword in interest.lower()) / len(keywords)
                features[idx] = min(match_score, 1.0)
        
        # ç¤¾åœ˜ç¶“æ­·
        achievements = student_data.get('achievements', [])
        club_mapping = {
            'club_leadership': ['ç¤¾é•·', 'æœƒé•·', 'å¹¹éƒ¨', 'é ˜å°'],
            'club_tech': ['è³‡è¨Š', 'ç¨‹å¼', 'é›»è…¦', 'ç§‘æŠ€'],
            'club_art': ['ç¾è¡“', 'è—è¡“', 'è¨­è¨ˆ', 'å‰µä½œ'],
            'club_sports': ['é‹å‹•', 'é«”è‚²', 'çƒéšŠ', 'å¥èº«'],
            'club_academic': ['å­¸è¡“', 'ç ”ç©¶', 'è®€æ›¸', 'ç«¶è³½']
        }
        
        for club_type, keywords in club_mapping.items():
            if club_type in self.feature_columns:
                idx = self.feature_columns.index(club_type)
                features[idx] = 1 if any(any(keyword in achievement.lower() 
                                           for keyword in keywords) 
                                       for achievement in achievements) else 0
        
        # ç«¶è³½ç²ç
        competition_mapping = {
            'competition_math': ['æ•¸å­¸', 'å¥§æ—åŒ¹äº', 'ç«¶è³½'],
            'competition_science': ['ç§‘å­¸', 'ç‰©ç†', 'åŒ–å­¸', 'ç”Ÿç‰©'],
            'competition_programming': ['ç¨‹å¼', 'è³‡è¨Š', 'è»Ÿé«”'],
            'competition_language': ['èªæ–‡', 'è‹±æ–‡', 'åœ‹æ–‡'],
            'competition_art': ['ç¾è¡“', 'è—è¡“', 'å‰µä½œ']
        }
        
        for comp_type, keywords in competition_mapping.items():
            if comp_type in self.feature_columns:
                idx = self.feature_columns.index(comp_type)
                features[idx] = 1 if any(any(keyword in achievement.lower() 
                                           for keyword in keywords) 
                                       for achievement in achievements) else 0
        
        return features.reshape(1, -1)
    
    def _predict_departments(self, features: np.ndarray) -> List[Tuple[str, float]]:
        """é æ¸¬å­¸ç³»"""
        # æ¨™æº–åŒ–ç‰¹å¾µ
        features_scaled = self.scaler.transform(features)
        
        # é æ¸¬æ©Ÿç‡
        probabilities = self.model.predict_proba(features_scaled)[0]
        
        # ç²å–é æ¸¬çµæœ
        predictions = []
        for i, prob in enumerate(probabilities):
            dept_name = self.departments[i]
            predictions.append((dept_name, prob))
        
        # æŒ‰æ©Ÿç‡æ’åº
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        return predictions
    
    def _generate_recommendations(self, predictions: List[Tuple[str, float]], 
                                student_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¨è–¦çµæœ"""
        recommendations = []
        
        # å­¸ç³»å°æ‡‰çš„å¤§å­¸å’Œå°ˆæ¥­
        dept_info = {
            'è³‡è¨Šå·¥ç¨‹å­¸ç³»': {
                'universities': ['åœ‹ç«‹å°ç£å¤§å­¸', 'åœ‹ç«‹æ¸…è¯å¤§å­¸', 'åœ‹ç«‹äº¤é€šå¤§å­¸', 'åœ‹ç«‹æˆåŠŸå¤§å­¸'],
                'majors': ['è»Ÿé«”å·¥ç¨‹', 'äººå·¥æ™ºæ…§', 'è³‡æ–™ç§‘å­¸', 'ç¶²è·¯å·¥ç¨‹']
            },
            'é›»æ©Ÿå·¥ç¨‹å­¸ç³»': {
                'universities': ['åœ‹ç«‹å°ç£å¤§å­¸', 'åœ‹ç«‹æ¸…è¯å¤§å­¸', 'åœ‹ç«‹äº¤é€šå¤§å­¸', 'åœ‹ç«‹æˆåŠŸå¤§å­¸'],
                'majors': ['é›»åŠ›å·¥ç¨‹', 'æ§åˆ¶å·¥ç¨‹', 'é€šè¨Šå·¥ç¨‹', 'é›»å­å·¥ç¨‹']
            },
            'å•†æ¥­ç®¡ç†å­¸ç³»': {
                'universities': ['åœ‹ç«‹æ”¿æ²»å¤§å­¸', 'åœ‹ç«‹å°ç£å¤§å­¸', 'åœ‹ç«‹æ¸…è¯å¤§å­¸', 'åœ‹ç«‹ä¸­å¤®å¤§å­¸'],
                'majors': ['ä¼æ¥­ç®¡ç†', 'è¡ŒéŠ·ç®¡ç†', 'äººåŠ›è³‡æºç®¡ç†', 'ç‡Ÿé‹ç®¡ç†']
            },
            'æ•¸å­¸ç³»': {
                'universities': ['åœ‹ç«‹å°ç£å¤§å­¸', 'åœ‹ç«‹æ¸…è¯å¤§å­¸', 'åœ‹ç«‹äº¤é€šå¤§å­¸', 'åœ‹ç«‹ä¸­å¤®å¤§å­¸'],
                'majors': ['æ‡‰ç”¨æ•¸å­¸', 'çµ±è¨ˆå­¸', 'è¨ˆç®—æ•¸å­¸', 'ç´”æ•¸å­¸']
            },
            'å¤–åœ‹èªæ–‡å­¸ç³»': {
                'universities': ['åœ‹ç«‹å°ç£å¤§å­¸', 'åœ‹ç«‹æ”¿æ²»å¤§å­¸', 'åœ‹ç«‹æ¸…è¯å¤§å­¸', 'åœ‹ç«‹ä¸­å¤®å¤§å­¸'],
                'majors': ['è‹±èªæ–‡å­¸', 'ç¿»è­¯', 'èªè¨€å­¸', 'æ¯”è¼ƒæ–‡å­¸']
            }
        }
        
        # ç”Ÿæˆå‰3åæ¨è–¦
        for i, (dept_name, score) in enumerate(predictions[:3]):
            if dept_name in dept_info:
                info = dept_info[dept_name]
                import random
                
                recommendation = {
                    'department': dept_name,
                    'university': random.choice(info['universities']),
                    'major': random.choice(info['majors']),
                    'score': round(score, 3),
                    'reason': self._generate_reason(dept_name, score, student_data),
                    'rank': i + 1
                }
                recommendations.append(recommendation)
        
        return recommendations
    
    def _generate_reason(self, dept_name: str, score: float, student_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¨è–¦ç†ç”±"""
        reasons = []
        
        # åŸºæ–¼åˆ†æ•¸çš„ç†ç”±
        if score > 0.8:
            reasons.append("AI åˆ†æé¡¯ç¤ºæ‚¨éå¸¸é©åˆæ­¤é ˜åŸŸ")
        elif score > 0.6:
            reasons.append("AI åˆ†æé¡¯ç¤ºæ‚¨é©åˆæ­¤é ˜åŸŸ")
        else:
            reasons.append("AI åˆ†æé¡¯ç¤ºæ­¤é ˜åŸŸå€¼å¾—è€ƒæ…®")
        
        # åŸºæ–¼æˆç¸¾çš„ç†ç”±
        academic_scores = student_data.get('academic_scores', {})
        if dept_name in ['è³‡è¨Šå·¥ç¨‹å­¸ç³»', 'é›»æ©Ÿå·¥ç¨‹å­¸ç³»', 'æ•¸å­¸ç³»']:
            if academic_scores.get('math', 0) >= 85:
                reasons.append("æ‚¨çš„æ•¸å­¸æˆç¸¾å„ªç§€")
            if academic_scores.get('science', 0) >= 85:
                reasons.append("æ‚¨çš„è‡ªç„¶ç§‘æˆç¸¾å„ªç•°")
        elif dept_name == 'å•†æ¥­ç®¡ç†å­¸ç³»':
            if academic_scores.get('chinese', 0) >= 85:
                reasons.append("æ‚¨çš„åœ‹æ–‡æˆç¸¾å„ªç§€")
            if academic_scores.get('english', 0) >= 85:
                reasons.append("æ‚¨çš„è‹±æ–‡èƒ½åŠ›ä½³")
        
        # åŸºæ–¼èˆˆè¶£çš„ç†ç”±
        interests = student_data.get('interests', [])
        if any('ç¨‹å¼' in interest or 'è³‡è¨Š' in interest for interest in interests):
            if dept_name in ['è³‡è¨Šå·¥ç¨‹å­¸ç³»', 'é›»æ©Ÿå·¥ç¨‹å­¸ç³»']:
                reasons.append("æ‚¨çš„èˆˆè¶£èˆ‡æ­¤é ˜åŸŸé«˜åº¦ç›¸é—œ")
        
        # é è¨­ç†ç”±
        if not reasons:
            reasons.append("æ ¹æ“šæ‚¨çš„æ•´é«”è¡¨ç¾ï¼Œæ­¤é ˜åŸŸé©åˆæ‚¨çš„ç™¼å±•æ½›åŠ›")
        
        return f"æ¨è–¦{dept_name}çš„åŸå› ï¼š{'; '.join(reasons[:2])}"

# å…¨åŸŸå¯¦ä¾‹
ai_recommendation = DepartmentRecommendationAI()

def analyze_student_data(data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """åˆ†æå­¸ç”Ÿè³‡æ–™ä¸¦ç”Ÿæˆæ¨è–¦ï¼ˆå°å¤–æ¥å£ï¼‰"""
    return ai_recommendation.analyze_student_data(data)
